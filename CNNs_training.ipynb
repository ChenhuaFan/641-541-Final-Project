{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "536587c6-010c-4230-82cd-2a8cc7b895b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from ASLDataset import ASLDataset\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from torchsummary import summary\n",
    "import torchvision.models as models\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc11422-2d83-4de7-9f7e-5b6e387f2355",
   "metadata": {},
   "source": [
    "The baseline model from scratch in 3.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "841d5737-e882-47f7-8586-765a0955f6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, **kwargs):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(self.bn(self.conv(x)))\n",
    "\n",
    "class BaselineModel(nn.Module):\n",
    "    def __init__(self, input_feature):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layer0 = nn.Sequential(\n",
    "            nn.Conv2d(input_feature, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            ConvBlock(64, 128, kernel_size=3, stride=2),\n",
    "            ConvBlock(128, 128, kernel_size=3, stride=2),\n",
    "            ConvBlock(128, 256, kernel_size=3, stride=2),\n",
    "            ConvBlock(256, 256, kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.gpool = torch.nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = torch.nn.Linear(256, 29)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.gpool(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af9264e-44a3-4c7d-aa85-3e408acfa08e",
   "metadata": {},
   "source": [
    "The Resnet style network from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "83fa9d38-0c6c-4bef-8a04-bc5bc54c8d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
    "        self.skip = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=2),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.skip(x)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(x + x1)\n",
    "        return x\n",
    "    \n",
    "class ResNetStyle(nn.Module):\n",
    "    def __init__(self, input_feature):\n",
    "        super().__init__()\n",
    "        self.layer0 = nn.Sequential(\n",
    "            nn.Conv2d(input_feature, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            ResBlock(64, 128),\n",
    "            ResBlock(128, 256),\n",
    "        )\n",
    "\n",
    "        self.gpool = torch.nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = torch.nn.Linear(256, 29)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.gpool(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d857de-71f1-41c7-b87d-d91a81249373",
   "metadata": {},
   "source": [
    "The Inception style network from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4c4ebeb1-f580-478f-b2f4-2211e0bd71db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, ch_1x1, ch_3x3_1, ch_3x3_2, ch_5x5_1, ch_5x5_2, ch_pool):\n",
    "        super().__init__()\n",
    "\n",
    "        self.p_1x1 = ConvBlock(in_channels, ch_1x1, kernel_size=1)\n",
    "\n",
    "        self.p_3x3_1 = ConvBlock(in_channels, ch_3x3_1, kernel_size=1)\n",
    "        self.p_3x3_2 = ConvBlock(ch_3x3_1, ch_3x3_2, kernel_size=3, padding=1)\n",
    "\n",
    "        self.p_5x5_1 = ConvBlock(in_channels, ch_5x5_1, kernel_size=1)\n",
    "        self.p_5x5_2 = ConvBlock(ch_5x5_1, ch_5x5_2, kernel_size=5, padding=2)\n",
    "\n",
    "        self.p_pool_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.p_pool_2 = ConvBlock(in_channels, ch_pool, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.p_1x1(x)\n",
    "\n",
    "        x2 = self.p_3x3_1(x)\n",
    "        x2 = self.p_3x3_2(x2)\n",
    "\n",
    "        x3 = self.p_5x5_1(x)\n",
    "        x3 = self.p_5x5_2(x3)\n",
    "\n",
    "        x4 = self.p_pool_1(x)\n",
    "        x4 = self.p_pool_2(x4)\n",
    "\n",
    "        x = torch.cat([x1, x2, x3, x4], 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class InceptionStyle(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer0 = nn.Sequential(\n",
    "            ConvBlock(in_channels, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "            ConvBlock(64, 192, kernel_size=3, stride=1, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "        )\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            InceptionBlock(192, 64, 96, 128, 16, 32, 32),\n",
    "            InceptionBlock(256, 128, 128, 192, 32, 96, 64)\n",
    "        )\n",
    "\n",
    "        self.gpool = torch.nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(480, 29)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.gpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4095792f-9662-4cc6-9814-4eb479f4a639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 100, 100]           9,472\n",
      "         MaxPool2d-2           [-1, 64, 50, 50]               0\n",
      "       BatchNorm2d-3           [-1, 64, 50, 50]             128\n",
      "              ReLU-4           [-1, 64, 50, 50]               0\n",
      "            Conv2d-5          [-1, 128, 25, 25]           8,320\n",
      "       BatchNorm2d-6          [-1, 128, 25, 25]             256\n",
      "            Conv2d-7          [-1, 128, 25, 25]          73,856\n",
      "       BatchNorm2d-8          [-1, 128, 25, 25]             256\n",
      "            Conv2d-9          [-1, 128, 25, 25]         147,584\n",
      "      BatchNorm2d-10          [-1, 128, 25, 25]             256\n",
      "         ResBlock-11          [-1, 128, 25, 25]               0\n",
      "           Conv2d-12          [-1, 256, 13, 13]          33,024\n",
      "      BatchNorm2d-13          [-1, 256, 13, 13]             512\n",
      "           Conv2d-14          [-1, 256, 13, 13]         295,168\n",
      "      BatchNorm2d-15          [-1, 256, 13, 13]             512\n",
      "           Conv2d-16          [-1, 256, 13, 13]         590,080\n",
      "      BatchNorm2d-17          [-1, 256, 13, 13]             512\n",
      "         ResBlock-18          [-1, 256, 13, 13]               0\n",
      "AdaptiveAvgPool2d-19            [-1, 256, 1, 1]               0\n",
      "           Linear-20                   [-1, 29]           7,453\n",
      "================================================================\n",
      "Total params: 1,167,389\n",
      "Trainable params: 1,167,389\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.46\n",
      "Forward/backward pass size (MB): 15.13\n",
      "Params size (MB): 4.45\n",
      "Estimated Total Size (MB): 20.04\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "resNetStyle = ResNetStyle(3).to(device)\n",
    "criterion_r = nn.CrossEntropyLoss()\n",
    "optimizer_r = optim.Adam(resNetStyle.parameters(), lr=0.01, weight_decay=0.001)\n",
    "scheduler_r = torch.optim.lr_scheduler.MultiStepLR(optimizer_r, milestones=[4,10,15], gamma=0.1)\n",
    "\n",
    "summary(resNetStyle,(3, 200, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ccba1a40-ea59-41ef-bdfe-af2d68178d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the train and test methods\n",
    "def train(model, data_loader, criterion, optimizer, scheduler):\n",
    "    \n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(data_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    \n",
    "    return running_loss / len(data_loader)\n",
    "\n",
    "\n",
    "def test(model, dataloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = model(images)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "33af915e-5175-4f34-9047-e0d8c783f9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")\n",
    "rotation = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.RandomRotation((-20, 20)),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")\n",
    "grayscale = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Grayscale(),\n",
    "     transforms.Normalize(0.5,0.5)]\n",
    ")\n",
    "\n",
    "trainset = ASLDataset('train',transform=no_transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=256,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = ASLDataset('test',transform=no_transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9539232-ba01-43fe-91c9-78f8c1ea85f0",
   "metadata": {},
   "source": [
    "Train the baseline model without preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "93004fcb-0939-4b6d-8f7f-5fde0a6a8908",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# baselineModel = BaselineModel(3).to(device)\n",
    "# criterion_b = nn.CrossEntropyLoss()\n",
    "# optimizer_b = optim.Adam(baselineModel.parameters(), lr=0.01, weight_decay=0.001)\n",
    "# scheduler_b = torch.optim.lr_scheduler.MultiStepLR(optimizer_b, milestones=[4,10,15], gamma=0.1)\n",
    "\n",
    "\n",
    "# summary(baselineModel,(3, 200, 200))\n",
    "\n",
    "# for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "#     start_time = time.time()\n",
    "#     train_loss = train(baselineModel, trainloader, criterion_b, optimizer_b, scheduler_b)\n",
    "#     test_acc = test(baselineModel, testloader)\n",
    "        \n",
    "#     print(f'Epoch: {epoch+1}, time used: {time.time()-start_time:.2f}s, training loss: {train_loss:.6f}, test accuracy:{test_acc:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "63ea3d74-7409-4553-a460-d6761f1a2ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(baselineModel.state_dict(), f'./trained_models/baselineModel_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a3498d-7aa6-4b10-8a4c-a7591f5ede58",
   "metadata": {},
   "source": [
    "The baseline model using grayscale preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4e05c128-6788-44ba-a5d7-a5691208bfd7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# trainset = ASLDataset('train',transform=grayscale)\n",
    "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=256,\n",
    "#                                           shuffle=True, num_workers=2)\n",
    "\n",
    "# testset = ASLDataset('test',transform=grayscale)\n",
    "# testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "#                                          shuffle=False, num_workers=2)\n",
    "\n",
    "# baselineModel = BaselineModel(1).to(device)\n",
    "# criterion_b = nn.CrossEntropyLoss()\n",
    "# optimizer_b = optim.Adam(baselineModel.parameters(), lr=0.01, weight_decay=0.001)\n",
    "# scheduler_b = torch.optim.lr_scheduler.MultiStepLR(optimizer_b, milestones=[4,10,15], gamma=0.1)\n",
    "\n",
    "\n",
    "# summary(baselineModel,(1, 200, 200))\n",
    "\n",
    "# for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "#     start_time = time.time()\n",
    "#     train_loss = train(baselineModel, trainloader, criterion_b, optimizer_b, scheduler_b)\n",
    "#     test_acc = test(baselineModel, testloader)\n",
    "        \n",
    "#     print(f'Epoch: {epoch+1}, time used: {time.time()-start_time:.2f}s, training loss: {train_loss:.6f}, test accuracy:{test_acc:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55f80cb-4cd2-4d18-bf69-67cfbeca72d3",
   "metadata": {},
   "source": [
    "The baseline model using rotation preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "20517303-d46d-4e33-b8f3-6d48feda79a8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# trainset = ASLDataset('train',transform=rotation)\n",
    "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=256,\n",
    "#                                           shuffle=True, num_workers=2)\n",
    "\n",
    "# testset = ASLDataset('test',transform=no_transform)\n",
    "# testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "#                                          shuffle=False, num_workers=2)\n",
    "\n",
    "# baselineModel = BaselineModel(3).to(device)\n",
    "# criterion_b = nn.CrossEntropyLoss()\n",
    "# optimizer_b = optim.Adam(baselineModel.parameters(), lr=0.01, weight_decay=0.001)\n",
    "# scheduler_b = torch.optim.lr_scheduler.MultiStepLR(optimizer_b, milestones=[4,10,15], gamma=0.1)\n",
    "\n",
    "\n",
    "# summary(baselineModel,(3, 200, 200))\n",
    "\n",
    "# for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "#     start_time = time.time()\n",
    "#     train_loss = train(baselineModel, trainloader, criterion_b, optimizer_b, scheduler_b)\n",
    "#     test_acc = test(baselineModel, testloader)\n",
    "        \n",
    "#     print(f'Epoch: {epoch+1}, time used: {time.time()-start_time:.2f}s, training loss: {train_loss:.6f}, test accuracy:{test_acc:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1d4642-7325-4d8f-ba22-9a618e6b7bea",
   "metadata": {},
   "source": [
    "Resnet style CNN without preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "26aba5ae-2f7b-4f28-ae13-4bd9e31a8519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainset = ASLDataset('train',transform=no_transform)\n",
    "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=256,\n",
    "#                                           shuffle=True, num_workers=1)\n",
    "\n",
    "# testset = ASLDataset('test',transform=no_transform)\n",
    "# testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "#                                          shuffle=False, num_workers=1)\n",
    "\n",
    "# resNetStyle = ResNetStyle(3).to(device)\n",
    "# criterion_r = nn.CrossEntropyLoss()\n",
    "# optimizer_r = optim.Adam(resNetStyle.parameters(), lr=0.01, weight_decay=0.001)\n",
    "# scheduler_r = torch.optim.lr_scheduler.MultiStepLR(optimizer_r, milestones=[4,10,15], gamma=0.1)\n",
    "\n",
    "\n",
    "# summary(resNetStyle,(3, 200, 200))\n",
    "\n",
    "# for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "#     start_time = time.time()\n",
    "#     train_loss = train(resNetStyle, trainloader, criterion_r, optimizer_r, scheduler_r)\n",
    "#     test_acc = test(resNetStyle, testloader)\n",
    "        \n",
    "#     print(f'Epoch: {epoch+1}, time used: {time.time()-start_time:.2f}s, training loss: {train_loss:.6f}, test accuracy:{test_acc:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36591595-783d-4695-b0ec-de580e26388c",
   "metadata": {},
   "source": [
    "Resnet style CNN without grayscale images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cb8b99f5-b24e-4d11-bdcf-420a673ba54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 100, 100]           3,200\n",
      "         MaxPool2d-2           [-1, 64, 50, 50]               0\n",
      "       BatchNorm2d-3           [-1, 64, 50, 50]             128\n",
      "              ReLU-4           [-1, 64, 50, 50]               0\n",
      "            Conv2d-5          [-1, 128, 25, 25]           8,320\n",
      "       BatchNorm2d-6          [-1, 128, 25, 25]             256\n",
      "            Conv2d-7          [-1, 128, 25, 25]          73,856\n",
      "       BatchNorm2d-8          [-1, 128, 25, 25]             256\n",
      "            Conv2d-9          [-1, 128, 25, 25]         147,584\n",
      "      BatchNorm2d-10          [-1, 128, 25, 25]             256\n",
      "         ResBlock-11          [-1, 128, 25, 25]               0\n",
      "           Conv2d-12          [-1, 256, 13, 13]          33,024\n",
      "      BatchNorm2d-13          [-1, 256, 13, 13]             512\n",
      "           Conv2d-14          [-1, 256, 13, 13]         295,168\n",
      "      BatchNorm2d-15          [-1, 256, 13, 13]             512\n",
      "           Conv2d-16          [-1, 256, 13, 13]         590,080\n",
      "      BatchNorm2d-17          [-1, 256, 13, 13]             512\n",
      "         ResBlock-18          [-1, 256, 13, 13]               0\n",
      "AdaptiveAvgPool2d-19            [-1, 256, 1, 1]               0\n",
      "           Linear-20                   [-1, 29]           7,453\n",
      "================================================================\n",
      "Total params: 1,161,117\n",
      "Trainable params: 1,161,117\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.15\n",
      "Forward/backward pass size (MB): 15.13\n",
      "Params size (MB): 4.43\n",
      "Estimated Total Size (MB): 19.71\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# trainset = ASLDataset('train',transform=grayscale)\n",
    "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=256,\n",
    "#                                           shuffle=True, num_workers=1)\n",
    "\n",
    "# testset = ASLDataset('test',transform=grayscale)\n",
    "# testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "#                                          shuffle=False, num_workers=1)\n",
    "\n",
    "resNetStyle = ResNetStyle(1).to(device)\n",
    "# criterion_r = nn.CrossEntropyLoss()\n",
    "# optimizer_r = optim.Adam(resNetStyle.parameters(), lr=0.01, weight_decay=0.001)\n",
    "# scheduler_r = torch.optim.lr_scheduler.MultiStepLR(optimizer_r, milestones=[4,10,15], gamma=0.1)\n",
    "\n",
    "\n",
    "summary(resNetStyle,(1, 200, 200))\n",
    "\n",
    "# for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "#     start_time = time.time()\n",
    "#     train_loss = train(resNetStyle, trainloader, criterion_r, optimizer_r, scheduler_r)\n",
    "#     test_acc = test(resNetStyle, testloader)\n",
    "        \n",
    "#     print(f'Epoch: {epoch+1}, time used: {time.time()-start_time:.2f}s, training loss: {train_loss:.6f}, test accuracy:{test_acc:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f428625-15d5-410d-9e8a-58011543490a",
   "metadata": {},
   "source": [
    "Inception style CNN without preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fada69c9-4bda-4947-bae7-cf04dbc55c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 100, 100]           9,472\n",
      "       BatchNorm2d-2         [-1, 64, 100, 100]             128\n",
      "              ReLU-3         [-1, 64, 100, 100]               0\n",
      "         ConvBlock-4         [-1, 64, 100, 100]               0\n",
      "         MaxPool2d-5           [-1, 64, 50, 50]               0\n",
      "            Conv2d-6          [-1, 192, 50, 50]         110,784\n",
      "       BatchNorm2d-7          [-1, 192, 50, 50]             384\n",
      "              ReLU-8          [-1, 192, 50, 50]               0\n",
      "         ConvBlock-9          [-1, 192, 50, 50]               0\n",
      "        MaxPool2d-10          [-1, 192, 25, 25]               0\n",
      "           Conv2d-11           [-1, 64, 25, 25]          12,352\n",
      "      BatchNorm2d-12           [-1, 64, 25, 25]             128\n",
      "             ReLU-13           [-1, 64, 25, 25]               0\n",
      "        ConvBlock-14           [-1, 64, 25, 25]               0\n",
      "           Conv2d-15           [-1, 96, 25, 25]          18,528\n",
      "      BatchNorm2d-16           [-1, 96, 25, 25]             192\n",
      "             ReLU-17           [-1, 96, 25, 25]               0\n",
      "        ConvBlock-18           [-1, 96, 25, 25]               0\n",
      "           Conv2d-19          [-1, 128, 25, 25]         110,720\n",
      "      BatchNorm2d-20          [-1, 128, 25, 25]             256\n",
      "             ReLU-21          [-1, 128, 25, 25]               0\n",
      "        ConvBlock-22          [-1, 128, 25, 25]               0\n",
      "           Conv2d-23           [-1, 16, 25, 25]           3,088\n",
      "      BatchNorm2d-24           [-1, 16, 25, 25]              32\n",
      "             ReLU-25           [-1, 16, 25, 25]               0\n",
      "        ConvBlock-26           [-1, 16, 25, 25]               0\n",
      "           Conv2d-27           [-1, 32, 25, 25]          12,832\n",
      "      BatchNorm2d-28           [-1, 32, 25, 25]              64\n",
      "             ReLU-29           [-1, 32, 25, 25]               0\n",
      "        ConvBlock-30           [-1, 32, 25, 25]               0\n",
      "        MaxPool2d-31          [-1, 192, 25, 25]               0\n",
      "           Conv2d-32           [-1, 32, 25, 25]           6,176\n",
      "      BatchNorm2d-33           [-1, 32, 25, 25]              64\n",
      "             ReLU-34           [-1, 32, 25, 25]               0\n",
      "        ConvBlock-35           [-1, 32, 25, 25]               0\n",
      "   InceptionBlock-36          [-1, 256, 25, 25]               0\n",
      "           Conv2d-37          [-1, 128, 25, 25]          32,896\n",
      "      BatchNorm2d-38          [-1, 128, 25, 25]             256\n",
      "             ReLU-39          [-1, 128, 25, 25]               0\n",
      "        ConvBlock-40          [-1, 128, 25, 25]               0\n",
      "           Conv2d-41          [-1, 128, 25, 25]          32,896\n",
      "      BatchNorm2d-42          [-1, 128, 25, 25]             256\n",
      "             ReLU-43          [-1, 128, 25, 25]               0\n",
      "        ConvBlock-44          [-1, 128, 25, 25]               0\n",
      "           Conv2d-45          [-1, 192, 25, 25]         221,376\n",
      "      BatchNorm2d-46          [-1, 192, 25, 25]             384\n",
      "             ReLU-47          [-1, 192, 25, 25]               0\n",
      "        ConvBlock-48          [-1, 192, 25, 25]               0\n",
      "           Conv2d-49           [-1, 32, 25, 25]           8,224\n",
      "      BatchNorm2d-50           [-1, 32, 25, 25]              64\n",
      "             ReLU-51           [-1, 32, 25, 25]               0\n",
      "        ConvBlock-52           [-1, 32, 25, 25]               0\n",
      "           Conv2d-53           [-1, 96, 25, 25]          76,896\n",
      "      BatchNorm2d-54           [-1, 96, 25, 25]             192\n",
      "             ReLU-55           [-1, 96, 25, 25]               0\n",
      "        ConvBlock-56           [-1, 96, 25, 25]               0\n",
      "        MaxPool2d-57          [-1, 256, 25, 25]               0\n",
      "           Conv2d-58           [-1, 64, 25, 25]          16,448\n",
      "      BatchNorm2d-59           [-1, 64, 25, 25]             128\n",
      "             ReLU-60           [-1, 64, 25, 25]               0\n",
      "        ConvBlock-61           [-1, 64, 25, 25]               0\n",
      "   InceptionBlock-62          [-1, 480, 25, 25]               0\n",
      "AdaptiveAvgPool2d-63            [-1, 480, 1, 1]               0\n",
      "           Linear-64                   [-1, 29]          13,949\n",
      "================================================================\n",
      "Total params: 689,165\n",
      "Trainable params: 689,165\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.46\n",
      "Forward/backward pass size (MB): 61.19\n",
      "Params size (MB): 2.63\n",
      "Estimated Total Size (MB): 64.28\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# trainset = ASLDataset('train',transform=no_transform)\n",
    "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=256,\n",
    "#                                           shuffle=True, num_workers=2)\n",
    "\n",
    "# testset = ASLDataset('test',transform=no_transform)\n",
    "# testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "#                                          shuffle=False, num_workers=2)\n",
    "inceptionStyle = InceptionStyle(3).to(device)\n",
    "# criterion_i = nn.CrossEntropyLoss()\n",
    "# optimizer_i = optim.Adam(inceptionStyle.parameters(), lr=0.01, weight_decay=0.001)\n",
    "# scheduler_i = torch.optim.lr_scheduler.MultiStepLR(optimizer_i, milestones=[4,10,15], gamma=0.1)\n",
    "\n",
    "\n",
    "summary(inceptionStyle,(3, 200, 200))\n",
    "\n",
    "# for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "#     start_time = time.time()\n",
    "#     train_loss = train(inceptionStyle, trainloader, criterion_i, optimizer_i, scheduler_i)\n",
    "#     test_acc = test(inceptionStyle, testloader)\n",
    "        \n",
    "#     print(f'Epoch: {epoch+1}, time used: {time.time()-start_time:.2f}s, training loss: {train_loss:.6f}, test accuracy:{test_acc:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15693954-b832-43d3-8d8f-f3536599074f",
   "metadata": {},
   "source": [
    "Inception style CNN with grayscale images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e285ca57-568e-49cc-9ccf-db943e56c060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainset = ASLDataset('train',transform=grayscale)\n",
    "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=256,\n",
    "#                                           shuffle=True, num_workers=2)\n",
    "\n",
    "# testset = ASLDataset('test',transform=grayscale)\n",
    "# testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "#                                          shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "# inceptionStyle = InceptionStyle(1).to(device)\n",
    "# criterion_i = nn.CrossEntropyLoss()\n",
    "# optimizer_i = optim.Adam(inceptionStyle.parameters(), lr=0.01, weight_decay=0.001)\n",
    "# scheduler_i = torch.optim.lr_scheduler.MultiStepLR(optimizer_i, milestones=[4,10,15], gamma=0.1)\n",
    "\n",
    "\n",
    "# summary(inceptionStyle,(1, 200, 200))\n",
    "\n",
    "# for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "#     start_time = time.time()\n",
    "#     train_loss = train(inceptionStyle, trainloader, criterion_i, optimizer_i, scheduler_i)\n",
    "#     test_acc = test(inceptionStyle, testloader)\n",
    "        \n",
    "#     print(f'Epoch: {epoch+1}, time used: {time.time()-start_time:.2f}s, training loss: {train_loss:.6f}, test accuracy:{test_acc:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a78d4f5-3710-48c7-a987-69ff6b193f59",
   "metadata": {},
   "source": [
    "Transfer learning using the Resnet18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "66db1236-0552-43cc-8c6a-6379e4e474fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224,224)),\n",
    "    # transforms.Gray(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]\n",
    ")\n",
    "\n",
    "trainset = ASLDataset('train',transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=256,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = ASLDataset('test',transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6a2cedaf-575a-4ee2-a89e-774108f0ae35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/12/09 14:58:23 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of pytorch. If you encounter errors during autologging, try upgrading / downgrading pytorch to a supported version, or try upgrading MLflow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, time used: 51.28s, training loss: 0.239103, test accuracy:0.711469\n",
      "Epoch: 2, time used: 51.66s, training loss: 0.061495, test accuracy:0.843561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/12/09 15:00:09 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed, possibly due older server version. The model artifacts have been logged successfully under ./mlruns/0/310e14e327aa4a36b8c557837bc74aea/artifacts. In addition to exporting model artifacts, MLflow clients 1.7.0 and above attempt to record model metadata to the tracking store. If logging to a mlflow server via REST, consider upgrading the server version to MLflow 1.7.0 or above. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n",
      "2022/12/09 15:00:12 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed, possibly due older server version. The model artifacts have been logged successfully under ./mlruns/0/310e14e327aa4a36b8c557837bc74aea/artifacts. In addition to exporting model artifacts, MLflow clients 1.7.0 and above attempt to record model metadata to the tracking store. If logging to a mlflow server via REST, consider upgrading the server version to MLflow 1.7.0 or above. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n",
      "Registered model 'ResNet' already exists. Creating a new version of this model...\n",
      "2022/12/09 15:00:12 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: ResNet, version 4\n",
      "Created version '4' of model 'ResNet'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: creation_timestamp=1670598012273, current_stage='None', description=None, last_updated_timestamp=1670598012273, name='ResNet', run_id='2d57b32efbee4c998e0f24c79f032118', run_link=None, source='./mlruns/0/2d57b32efbee4c998e0f24c79f032118/artifacts/model_output', status='READY', status_message=None, tags={}, user_id=None, version=4>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow.pytorch\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in resnet.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "num_ftrs = resnet.fc.in_features\n",
    "resnet.fc = nn.Linear(num_ftrs, 29)\n",
    "resnet.to(device)\n",
    "\n",
    "# summary(resnet, (3,224,224))\n",
    "\n",
    "criterion_t_r = nn.CrossEntropyLoss()\n",
    "optimizer_t_r = optim.Adam(filter(lambda p: p.requires_grad, resnet.parameters()), lr=0.01, weight_decay=0.001)\n",
    "scheduler_t_r = torch.optim.lr_scheduler.MultiStepLR(optimizer_t_r, milestones=[4,10,15], gamma=0.1)\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///641.db\")\n",
    "mlflow.set_registry_uri(\"sqlite:///641.db\")\n",
    "client = MlflowClient(tracking_uri=\"sqlite:///641.db\")\n",
    "\n",
    "run = client.create_run(experiment_id='0')\n",
    "\n",
    "mlflow.pytorch.autolog()\n",
    "\n",
    "# training\n",
    "# loop over the dataset multiple times\n",
    "for epoch in range(2):  \n",
    "    \n",
    "    start_time = time.time()\n",
    "    train_loss = train(resnet, trainloader, criterion_t_r, optimizer_t_r, scheduler_t_r)\n",
    "    test_acc = test(resnet, testloader)\n",
    "\n",
    "    client.log_metric(run.info.run_id, \"test_acc\", test_acc, step=epoch)\n",
    "    client.log_metric(run.info.run_id, \"train_loss\", train_loss, step=epoch)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1}, time used: {time.time()-start_time:.2f}s, training loss: {train_loss:.6f}, test accuracy:{test_acc:.6f}')\n",
    "\n",
    "# log\n",
    "mlflow.pytorch.log_model(resnet, \"model_output\")\n",
    "# convert to scripted model and log the model\n",
    "scripted_pytorch_resnet = torch.jit.script(resnet)\n",
    "mlflow.pytorch.log_model(scripted_pytorch_resnet, \"scripted_model\")\n",
    "# save\n",
    "model_uri = f'runs:/{run.info.run_id}/model_output'\n",
    "mlflow.register_model(model_uri, \"ResNet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d996cbc1-8edc-409c-b8e2-2c0c1e739222",
   "metadata": {},
   "source": [
    "Transfer learning using the InceptionV3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5ae322c3-7c9c-4f7b-9b85-b40eb072bfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inception = models.inception_v3(pretrained=True)\n",
    "\n",
    "# for param in inception.parameters():\n",
    "#     param.requires_grad = False\n",
    "# for param in inception.Mixed_7c.parameters():\n",
    "#     param.requires_grad = True\n",
    "    \n",
    "# num_ftrs = inception.fc.in_features\n",
    "# inception.fc = nn.Linear(num_ftrs, 29)\n",
    "# inception.to(device)\n",
    "# print(inception)\n",
    "# summary(inception, (3,299,299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f39bc1ad-342b-4680-8575-37797be9fb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_inc(model, data_loader, criterion, optimizer, scheduler):\n",
    "    \n",
    "#     model.train()\n",
    "#     running_loss = 0.0\n",
    "\n",
    "#     for i, data in enumerate(data_loader, 0):\n",
    "#         inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs, aux_output = model(inputs)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         running_loss += loss.item()\n",
    "    \n",
    "#     scheduler.step()\n",
    "    \n",
    "    \n",
    "#     return running_loss / len(data_loader)\n",
    "\n",
    "\n",
    "# def test_inc(model, dataloader):\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     model.eval()\n",
    "#     # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "#     with torch.no_grad():\n",
    "#         for data in dataloader:\n",
    "#             images, labels = data[0].to(device), data[1].to(device)\n",
    "#             # calculate outputs by running images through the network\n",
    "#             outputs, aux_output = model(images)\n",
    "#             # the class with the highest energy is what we choose as prediction\n",
    "#             _, predicted = torch.max(outputs.data, 1)\n",
    "#             total += labels.size(0)\n",
    "#             correct += (predicted == labels).sum().item()\n",
    "    \n",
    "#     return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b138a358-6765-4026-a070-14b9e3b7c433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = transforms.Compose(\n",
    "#     [transforms.ToTensor(),\n",
    "#      transforms.Resize((299,299)),\n",
    "#      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]\n",
    "# )\n",
    "\n",
    "# trainset = ASLDataset('train',transform=transform)\n",
    "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=256,\n",
    "#                                           shuffle=True, num_workers=2)\n",
    "\n",
    "# testset = ASLDataset('test',transform=transform)\n",
    "# testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "#                                          shuffle=False, num_workers=2)\n",
    "\n",
    "# criterion_t_i = nn.CrossEntropyLoss()\n",
    "# optimizer_t_i = optim.Adam(filter(lambda p: p.requires_grad, inception.parameters()), lr=0.01, weight_decay=0.001)\n",
    "# scheduler_t_i = torch.optim.lr_scheduler.MultiStepLR(optimizer_t_i, milestones=[4,10,15], gamma=0.1)\n",
    "\n",
    "\n",
    "# for epoch in range(20):  # loop over the dataset multiple times\n",
    "    \n",
    "#     start_time = time.time()\n",
    "#     train_loss = train_inc(inception, trainloader, criterion_t_i, optimizer_t_i, scheduler_t_i)\n",
    "#     test_acc = test(inception, testloader)\n",
    "    \n",
    "#     print(f'Epoch: {epoch+1}, time used: {time.time()-start_time:.2f}s, training loss: {train_loss:.6f}, test accuracy:{test_acc:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e0254c5f-1d7a-4295-8c7f-e2194a1bd4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(inception.state_dict(), f'./trained_models/inception_raw.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66810be5-5cfd-42d1-ab2e-c13c0f20a7b1",
   "metadata": {},
   "source": [
    "Transfer learning using the efficientnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "20bff1a5-9502-480a-991b-f770f6cafdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# efficientnet = models.efficientnet_b0(pretrained=True)\n",
    "\n",
    "# for param in efficientnet.parameters():\n",
    "#     param.requires_grad = False\n",
    "# for param in efficientnet.features[8].parameters():\n",
    "#     param.requires_grad = True\n",
    "    \n",
    "# num_ftrs = efficientnet.classifier[1].in_features\n",
    "# efficientnet.classifier[1] = nn.Linear(num_ftrs, 29)\n",
    "# efficientnet.to(device)\n",
    "# print(efficientnet)\n",
    "# summary(efficientnet, (3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "99f51a71-7d89-4533-824b-d854bc52f557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = transforms.Compose(\n",
    "#     [transforms.ToTensor(),\n",
    "#      transforms.Resize((224,224)),\n",
    "#      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]\n",
    "# )\n",
    "\n",
    "# trainset = ASLDataset('train',transform=transform)\n",
    "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=256,\n",
    "#                                           shuffle=True, num_workers=2)\n",
    "\n",
    "# testset = ASLDataset('test',transform=transform)\n",
    "# testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "#                                          shuffle=False, num_workers=2)\n",
    "\n",
    "# criterion_t_e = nn.CrossEntropyLoss()\n",
    "# optimizer_t_e = optim.Adam(filter(lambda p: p.requires_grad, efficientnet.parameters()), lr=0.01, weight_decay=0.001)\n",
    "# scheduler_t_e = torch.optim.lr_scheduler.MultiStepLR(optimizer_t_e, milestones=[4,10,15], gamma=0.1)\n",
    "\n",
    "\n",
    "# for epoch in range(20):  # loop over the dataset multiple times\n",
    "    \n",
    "#     start_time = time.time()\n",
    "#     train_loss = train(efficientnet, trainloader, criterion_t_e, optimizer_t_e, scheduler_t_e)\n",
    "#     test_acc = test(efficientnet, testloader)\n",
    "    \n",
    "#     print(f'Epoch: {epoch+1}, time used: {time.time()-start_time:.2f}s, training loss: {train_loss:.6f}, test accuracy:{test_acc:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e51118-d4c0-4fe7-a8c3-01845ba8b9ae",
   "metadata": {},
   "source": [
    "Transfer learning using the mobilenet_v3_small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0137776f-c313-451d-8c4b-d2fcbbd505fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mobilenet_v3_small = models.mobilenet_v3_small(pretrained=False)\n",
    "# mobilenet_v3_small.load_state_dict(torch.load('./trained_models/mobilenet_v3_small-047dcff4.pth'))\n",
    "\n",
    "# for param in mobilenet_v3_small.features.parameters():\n",
    "#     param.requires_grad = False\n",
    "# for param in mobilenet_v3_small.features[12].parameters():\n",
    "#     param.requires_grad = True\n",
    "    \n",
    "# num_ftrs = mobilenet_v3_small.classifier[3].in_features\n",
    "# mobilenet_v3_small.classifier[3] = nn.Linear(num_ftrs, 29)\n",
    "# mobilenet_v3_small.to(device)\n",
    "# print(mobilenet_v3_small)\n",
    "# summary(mobilenet_v3_small, (3,224,224))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b8cedd16-4a17-4268-9deb-c5df092be6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = transforms.Compose(\n",
    "#     [transforms.ToTensor(),\n",
    "#      transforms.Resize((224,224)),\n",
    "#      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]\n",
    "# )\n",
    "\n",
    "# trainset = ASLDataset('train',transform=transform)\n",
    "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=256,\n",
    "#                                           shuffle=True, num_workers=2)\n",
    "\n",
    "# testset = ASLDataset('test',transform=transform)\n",
    "# testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "#                                          shuffle=False, num_workers=2)\n",
    "\n",
    "# criterion_t_m = nn.CrossEntropyLoss()\n",
    "# optimizer_t_m = optim.Adam(filter(lambda p: p.requires_grad, mobilenet_v3_small.parameters()), lr=0.01, weight_decay=0.001)\n",
    "# scheduler_t_m = torch.optim.lr_scheduler.MultiStepLR(optimizer_t_m, milestones=[4,10,15], gamma=0.1)\n",
    "\n",
    "\n",
    "# for epoch in range(20):  # loop over the dataset multiple times\n",
    "    \n",
    "#     start_time = time.time()\n",
    "#     train_loss = train(mobilenet_v3_small, trainloader, criterion_t_m, optimizer_t_m, scheduler_t_m)\n",
    "#     test_acc = test(mobilenet_v3_small, testloader)\n",
    "    \n",
    "#     print(f'Epoch: {epoch+1}, time used: {time.time()-start_time:.2f}s, training loss: {train_loss:.6f}, test accuracy:{test_acc:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96fa2d1-8313-4cfc-b1d1-a4b6768d222a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('cnn2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "53b1cc22c89150dad8df01a0b7e8e9b3f92e60ec72dccd9137866dd2a3a9ae73"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
