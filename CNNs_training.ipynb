{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "536587c6-010c-4230-82cd-2a8cc7b895b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam/anaconda3/envs/cnn2/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from ASLDataset import ASLDataset\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from torchsummary import summary\n",
    "import torchvision.models as models\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc11422-2d83-4de7-9f7e-5b6e387f2355",
   "metadata": {},
   "source": [
    "The baseline model from scratch in 3.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "841d5737-e882-47f7-8586-765a0955f6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, **kwargs):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(self.bn(self.conv(x)))\n",
    "\n",
    "class BaselineModel(nn.Module):\n",
    "    def __init__(self, input_feature):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layer0 = nn.Sequential(\n",
    "            nn.Conv2d(input_feature, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            ConvBlock(64, 128, kernel_size=3, stride=2),\n",
    "            ConvBlock(128, 128, kernel_size=3, stride=2),\n",
    "            ConvBlock(128, 256, kernel_size=3, stride=2),\n",
    "            ConvBlock(256, 256, kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.gpool = torch.nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = torch.nn.Linear(256, 29)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.gpool(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af9264e-44a3-4c7d-aa85-3e408acfa08e",
   "metadata": {},
   "source": [
    "The Resnet style network from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83fa9d38-0c6c-4bef-8a04-bc5bc54c8d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
    "        self.skip = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=2),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.skip(x)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(x + x1)\n",
    "        return x\n",
    "    \n",
    "class ResNetStyle(nn.Module):\n",
    "    def __init__(self, input_feature):\n",
    "        super().__init__()\n",
    "        self.layer0 = nn.Sequential(\n",
    "            nn.Conv2d(input_feature, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            ResBlock(64, 128),\n",
    "            ResBlock(128, 256),\n",
    "        )\n",
    "\n",
    "        self.gpool = torch.nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = torch.nn.Linear(256, 29)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.gpool(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d857de-71f1-41c7-b87d-d91a81249373",
   "metadata": {},
   "source": [
    "The Inception style network from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c4ebeb1-f580-478f-b2f4-2211e0bd71db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, ch_1x1, ch_3x3_1, ch_3x3_2, ch_5x5_1, ch_5x5_2, ch_pool):\n",
    "        super().__init__()\n",
    "\n",
    "        self.p_1x1 = ConvBlock(in_channels, ch_1x1, kernel_size=1)\n",
    "\n",
    "        self.p_3x3_1 = ConvBlock(in_channels, ch_3x3_1, kernel_size=1)\n",
    "        self.p_3x3_2 = ConvBlock(ch_3x3_1, ch_3x3_2, kernel_size=3, padding=1)\n",
    "\n",
    "        self.p_5x5_1 = ConvBlock(in_channels, ch_5x5_1, kernel_size=1)\n",
    "        self.p_5x5_2 = ConvBlock(ch_5x5_1, ch_5x5_2, kernel_size=5, padding=2)\n",
    "\n",
    "        self.p_pool_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.p_pool_2 = ConvBlock(in_channels, ch_pool, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.p_1x1(x)\n",
    "\n",
    "        x2 = self.p_3x3_1(x)\n",
    "        x2 = self.p_3x3_2(x2)\n",
    "\n",
    "        x3 = self.p_5x5_1(x)\n",
    "        x3 = self.p_5x5_2(x3)\n",
    "\n",
    "        x4 = self.p_pool_1(x)\n",
    "        x4 = self.p_pool_2(x4)\n",
    "\n",
    "        x = torch.cat([x1, x2, x3, x4], 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class InceptionStyle(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer0 = nn.Sequential(\n",
    "            ConvBlock(in_channels, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "            ConvBlock(64, 192, kernel_size=3, stride=1, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "        )\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            InceptionBlock(192, 64, 96, 128, 16, 32, 32),\n",
    "            InceptionBlock(256, 128, 128, 192, 32, 96, 64)\n",
    "        )\n",
    "\n",
    "        self.gpool = torch.nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(480, 29)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.gpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4095792f-9662-4cc6-9814-4eb479f4a639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 100, 100]           9,472\n",
      "         MaxPool2d-2           [-1, 64, 50, 50]               0\n",
      "       BatchNorm2d-3           [-1, 64, 50, 50]             128\n",
      "              ReLU-4           [-1, 64, 50, 50]               0\n",
      "            Conv2d-5          [-1, 128, 25, 25]           8,320\n",
      "       BatchNorm2d-6          [-1, 128, 25, 25]             256\n",
      "            Conv2d-7          [-1, 128, 25, 25]          73,856\n",
      "       BatchNorm2d-8          [-1, 128, 25, 25]             256\n",
      "            Conv2d-9          [-1, 128, 25, 25]         147,584\n",
      "      BatchNorm2d-10          [-1, 128, 25, 25]             256\n",
      "         ResBlock-11          [-1, 128, 25, 25]               0\n",
      "           Conv2d-12          [-1, 256, 13, 13]          33,024\n",
      "      BatchNorm2d-13          [-1, 256, 13, 13]             512\n",
      "           Conv2d-14          [-1, 256, 13, 13]         295,168\n",
      "      BatchNorm2d-15          [-1, 256, 13, 13]             512\n",
      "           Conv2d-16          [-1, 256, 13, 13]         590,080\n",
      "      BatchNorm2d-17          [-1, 256, 13, 13]             512\n",
      "         ResBlock-18          [-1, 256, 13, 13]               0\n",
      "AdaptiveAvgPool2d-19            [-1, 256, 1, 1]               0\n",
      "           Linear-20                   [-1, 29]           7,453\n",
      "================================================================\n",
      "Total params: 1,167,389\n",
      "Trainable params: 1,167,389\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.46\n",
      "Forward/backward pass size (MB): 15.13\n",
      "Params size (MB): 4.45\n",
      "Estimated Total Size (MB): 20.04\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "resNetStyle = ResNetStyle(3).to(device)\n",
    "criterion_r = nn.CrossEntropyLoss()\n",
    "optimizer_r = optim.Adam(resNetStyle.parameters(), lr=0.01, weight_decay=0.001)\n",
    "scheduler_r = torch.optim.lr_scheduler.MultiStepLR(optimizer_r, milestones=[4,10,15], gamma=0.1)\n",
    "\n",
    "summary(resNetStyle,(3, 200, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccba1a40-ea59-41ef-bdfe-af2d68178d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the train and test methods\n",
    "def train(model, data_loader, criterion, optimizer, scheduler):\n",
    "    \n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(data_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    \n",
    "    return running_loss / len(data_loader)\n",
    "\n",
    "\n",
    "def test(model, dataloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = model(images)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33af915e-5175-4f34-9047-e0d8c783f9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")\n",
    "rotation = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.RandomRotation((-20, 20)),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")\n",
    "grayscale = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Grayscale(),\n",
    "     transforms.Normalize(0.5,0.5)]\n",
    ")\n",
    "\n",
    "trainset = ASLDataset('train',transform=no_transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=256,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = ASLDataset('test',transform=no_transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9539232-ba01-43fe-91c9-78f8c1ea85f0",
   "metadata": {},
   "source": [
    "Train the baseline model without preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93004fcb-0939-4b6d-8f7f-5fde0a6a8908",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 100, 100]           9,472\n",
      "         MaxPool2d-2           [-1, 64, 50, 50]               0\n",
      "       BatchNorm2d-3           [-1, 64, 50, 50]             128\n",
      "              ReLU-4           [-1, 64, 50, 50]               0\n",
      "            Conv2d-5          [-1, 128, 24, 24]          73,856\n",
      "       BatchNorm2d-6          [-1, 128, 24, 24]             256\n",
      "              ReLU-7          [-1, 128, 24, 24]               0\n",
      "         ConvBlock-8          [-1, 128, 24, 24]               0\n",
      "            Conv2d-9          [-1, 128, 11, 11]         147,584\n",
      "      BatchNorm2d-10          [-1, 128, 11, 11]             256\n",
      "             ReLU-11          [-1, 128, 11, 11]               0\n",
      "        ConvBlock-12          [-1, 128, 11, 11]               0\n",
      "           Conv2d-13            [-1, 256, 5, 5]         295,168\n",
      "      BatchNorm2d-14            [-1, 256, 5, 5]             512\n",
      "             ReLU-15            [-1, 256, 5, 5]               0\n",
      "        ConvBlock-16            [-1, 256, 5, 5]               0\n",
      "           Conv2d-17            [-1, 256, 2, 2]         590,080\n",
      "      BatchNorm2d-18            [-1, 256, 2, 2]             512\n",
      "             ReLU-19            [-1, 256, 2, 2]               0\n",
      "        ConvBlock-20            [-1, 256, 2, 2]               0\n",
      "AdaptiveAvgPool2d-21            [-1, 256, 1, 1]               0\n",
      "           Linear-22                   [-1, 29]           7,453\n",
      "================================================================\n",
      "Total params: 1,125,277\n",
      "Trainable params: 1,125,277\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.46\n",
      "Forward/backward pass size (MB): 11.50\n",
      "Params size (MB): 4.29\n",
      "Estimated Total Size (MB): 16.25\n",
      "----------------------------------------------------------------\n",
      "Epoch: 1, time used: 25.90s, training loss: 0.618397, test accuracy:0.516580\n",
      "Epoch: 2, time used: 24.53s, training loss: 0.108634, test accuracy:0.672249\n",
      "Epoch: 3, time used: 24.41s, training loss: 0.079084, test accuracy:0.598546\n",
      "Epoch: 4, time used: 24.40s, training loss: 0.080031, test accuracy:0.730087\n",
      "Epoch: 5, time used: 24.60s, training loss: 0.015083, test accuracy:0.809298\n",
      "Epoch: 6, time used: 24.60s, training loss: 0.011455, test accuracy:0.809519\n",
      "Epoch: 7, time used: 24.55s, training loss: 0.013054, test accuracy:0.806324\n",
      "Epoch: 8, time used: 24.69s, training loss: 0.014907, test accuracy:0.809959\n",
      "Epoch: 9, time used: 24.39s, training loss: 0.014278, test accuracy:0.796519\n",
      "Epoch: 10, time used: 24.55s, training loss: 0.014524, test accuracy:0.807866\n",
      "Epoch: 11, time used: 24.68s, training loss: 0.009108, test accuracy:0.819985\n",
      "Epoch: 12, time used: 24.60s, training loss: 0.008017, test accuracy:0.820756\n",
      "Epoch: 13, time used: 24.65s, training loss: 0.008358, test accuracy:0.820425\n",
      "Epoch: 14, time used: 24.49s, training loss: 0.008883, test accuracy:0.814917\n",
      "Epoch: 15, time used: 24.49s, training loss: 0.009279, test accuracy:0.815908\n",
      "Epoch: 16, time used: 24.50s, training loss: 0.009109, test accuracy:0.818993\n",
      "Epoch: 17, time used: 24.71s, training loss: 0.008970, test accuracy:0.815357\n",
      "Epoch: 18, time used: 24.55s, training loss: 0.008979, test accuracy:0.818332\n",
      "Epoch: 19, time used: 24.72s, training loss: 0.009112, test accuracy:0.816129\n",
      "Epoch: 20, time used: 24.69s, training loss: 0.009112, test accuracy:0.816459\n"
     ]
    }
   ],
   "source": [
    "baselineModel = BaselineModel(3).to(device)\n",
    "criterion_b = nn.CrossEntropyLoss()\n",
    "optimizer_b = optim.Adam(baselineModel.parameters(), lr=0.01, weight_decay=0.001)\n",
    "scheduler_b = torch.optim.lr_scheduler.MultiStepLR(optimizer_b, milestones=[4,10,15], gamma=0.1)\n",
    "\n",
    "\n",
    "summary(baselineModel,(3, 200, 200))\n",
    "\n",
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "    start_time = time.time()\n",
    "    train_loss = train(baselineModel, trainloader, criterion_b, optimizer_b, scheduler_b)\n",
    "    test_acc = test(baselineModel, testloader)\n",
    "        \n",
    "    print(f'Epoch: {epoch+1}, time used: {time.time()-start_time:.2f}s, training loss: {train_loss:.6f}, test accuracy:{test_acc:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63ea3d74-7409-4553-a460-d6761f1a2ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(baselineModel.state_dict(), f'./trained_models/baselineModel_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a3498d-7aa6-4b10-8a4c-a7591f5ede58",
   "metadata": {},
   "source": [
    "The baseline model using grayscale preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e05c128-6788-44ba-a5d7-a5691208bfd7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 100, 100]           3,200\n",
      "         MaxPool2d-2           [-1, 64, 50, 50]               0\n",
      "       BatchNorm2d-3           [-1, 64, 50, 50]             128\n",
      "              ReLU-4           [-1, 64, 50, 50]               0\n",
      "            Conv2d-5          [-1, 128, 24, 24]          73,856\n",
      "       BatchNorm2d-6          [-1, 128, 24, 24]             256\n",
      "              ReLU-7          [-1, 128, 24, 24]               0\n",
      "         ConvBlock-8          [-1, 128, 24, 24]               0\n",
      "            Conv2d-9          [-1, 128, 11, 11]         147,584\n",
      "      BatchNorm2d-10          [-1, 128, 11, 11]             256\n",
      "             ReLU-11          [-1, 128, 11, 11]               0\n",
      "        ConvBlock-12          [-1, 128, 11, 11]               0\n",
      "           Conv2d-13            [-1, 256, 5, 5]         295,168\n",
      "      BatchNorm2d-14            [-1, 256, 5, 5]             512\n",
      "             ReLU-15            [-1, 256, 5, 5]               0\n",
      "        ConvBlock-16            [-1, 256, 5, 5]               0\n",
      "           Conv2d-17            [-1, 256, 2, 2]         590,080\n",
      "      BatchNorm2d-18            [-1, 256, 2, 2]             512\n",
      "             ReLU-19            [-1, 256, 2, 2]               0\n",
      "        ConvBlock-20            [-1, 256, 2, 2]               0\n",
      "AdaptiveAvgPool2d-21            [-1, 256, 1, 1]               0\n",
      "           Linear-22                   [-1, 29]           7,453\n",
      "================================================================\n",
      "Total params: 1,119,005\n",
      "Trainable params: 1,119,005\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.15\n",
      "Forward/backward pass size (MB): 11.50\n",
      "Params size (MB): 4.27\n",
      "Estimated Total Size (MB): 15.92\n",
      "----------------------------------------------------------------\n",
      "Epoch: 1, time used: 20.50s, training loss: 0.644703, test accuracy:0.452022\n",
      "Epoch: 2, time used: 20.62s, training loss: 0.125070, test accuracy:0.653189\n",
      "Epoch: 3, time used: 20.46s, training loss: 0.090421, test accuracy:0.721163\n",
      "Epoch: 4, time used: 20.78s, training loss: 0.077144, test accuracy:0.729316\n",
      "Epoch: 5, time used: 20.22s, training loss: 0.017010, test accuracy:0.803680\n",
      "Epoch: 6, time used: 20.48s, training loss: 0.011174, test accuracy:0.805112\n",
      "Epoch: 7, time used: 20.59s, training loss: 0.012877, test accuracy:0.801036\n",
      "Epoch: 8, time used: 21.01s, training loss: 0.013977, test accuracy:0.797731\n",
      "Epoch: 9, time used: 20.46s, training loss: 0.014110, test accuracy:0.798612\n",
      "Epoch: 10, time used: 20.44s, training loss: 0.016519, test accuracy:0.808637\n",
      "Epoch: 11, time used: 20.59s, training loss: 0.007866, test accuracy:0.806764\n",
      "Epoch: 12, time used: 20.24s, training loss: 0.007645, test accuracy:0.807646\n",
      "Epoch: 13, time used: 20.17s, training loss: 0.007919, test accuracy:0.806103\n",
      "Epoch: 14, time used: 20.42s, training loss: 0.008525, test accuracy:0.808527\n",
      "Epoch: 15, time used: 20.48s, training loss: 0.008872, test accuracy:0.808197\n",
      "Epoch: 16, time used: 20.30s, training loss: 0.008671, test accuracy:0.807536\n",
      "Epoch: 17, time used: 20.62s, training loss: 0.008669, test accuracy:0.807425\n",
      "Epoch: 18, time used: 20.38s, training loss: 0.008742, test accuracy:0.806103\n",
      "Epoch: 19, time used: 20.41s, training loss: 0.008749, test accuracy:0.806544\n",
      "Epoch: 20, time used: 20.55s, training loss: 0.008768, test accuracy:0.806324\n"
     ]
    }
   ],
   "source": [
    "trainset = ASLDataset('train',transform=grayscale)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=256,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = ASLDataset('test',transform=grayscale)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "baselineModel = BaselineModel(1).to(device)\n",
    "criterion_b = nn.CrossEntropyLoss()\n",
    "optimizer_b = optim.Adam(baselineModel.parameters(), lr=0.01, weight_decay=0.001)\n",
    "scheduler_b = torch.optim.lr_scheduler.MultiStepLR(optimizer_b, milestones=[4,10,15], gamma=0.1)\n",
    "\n",
    "\n",
    "summary(baselineModel,(1, 200, 200))\n",
    "\n",
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "    start_time = time.time()\n",
    "    train_loss = train(baselineModel, trainloader, criterion_b, optimizer_b, scheduler_b)\n",
    "    test_acc = test(baselineModel, testloader)\n",
    "        \n",
    "    print(f'Epoch: {epoch+1}, time used: {time.time()-start_time:.2f}s, training loss: {train_loss:.6f}, test accuracy:{test_acc:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55f80cb-4cd2-4d18-bf69-67cfbeca72d3",
   "metadata": {},
   "source": [
    "The baseline model using rotation preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20517303-d46d-4e33-b8f3-6d48feda79a8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 100, 100]           9,472\n",
      "         MaxPool2d-2           [-1, 64, 50, 50]               0\n",
      "       BatchNorm2d-3           [-1, 64, 50, 50]             128\n",
      "              ReLU-4           [-1, 64, 50, 50]               0\n",
      "            Conv2d-5          [-1, 128, 24, 24]          73,856\n",
      "       BatchNorm2d-6          [-1, 128, 24, 24]             256\n",
      "              ReLU-7          [-1, 128, 24, 24]               0\n",
      "         ConvBlock-8          [-1, 128, 24, 24]               0\n",
      "            Conv2d-9          [-1, 128, 11, 11]         147,584\n",
      "      BatchNorm2d-10          [-1, 128, 11, 11]             256\n",
      "             ReLU-11          [-1, 128, 11, 11]               0\n",
      "        ConvBlock-12          [-1, 128, 11, 11]               0\n",
      "           Conv2d-13            [-1, 256, 5, 5]         295,168\n",
      "      BatchNorm2d-14            [-1, 256, 5, 5]             512\n",
      "             ReLU-15            [-1, 256, 5, 5]               0\n",
      "        ConvBlock-16            [-1, 256, 5, 5]               0\n",
      "           Conv2d-17            [-1, 256, 2, 2]         590,080\n",
      "      BatchNorm2d-18            [-1, 256, 2, 2]             512\n",
      "             ReLU-19            [-1, 256, 2, 2]               0\n",
      "        ConvBlock-20            [-1, 256, 2, 2]               0\n",
      "AdaptiveAvgPool2d-21            [-1, 256, 1, 1]               0\n",
      "           Linear-22                   [-1, 29]           7,453\n",
      "================================================================\n",
      "Total params: 1,125,277\n",
      "Trainable params: 1,125,277\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.46\n",
      "Forward/backward pass size (MB): 11.50\n",
      "Params size (MB): 4.29\n",
      "Estimated Total Size (MB): 16.25\n",
      "----------------------------------------------------------------\n",
      "Epoch: 1, time used: 55.00s, training loss: 0.778021, test accuracy:0.304616\n",
      "Epoch: 2, time used: 54.83s, training loss: 0.201880, test accuracy:0.576292\n",
      "Epoch: 3, time used: 54.93s, training loss: 0.159879, test accuracy:0.575961\n",
      "Epoch: 4, time used: 54.99s, training loss: 0.135628, test accuracy:0.639969\n",
      "Epoch: 5, time used: 55.15s, training loss: 0.037636, test accuracy:0.783298\n",
      "Epoch: 6, time used: 54.84s, training loss: 0.022800, test accuracy:0.777680\n",
      "Epoch: 7, time used: 55.16s, training loss: 0.022027, test accuracy:0.775036\n",
      "Epoch: 8, time used: 54.92s, training loss: 0.025660, test accuracy:0.782307\n",
      "Epoch: 9, time used: 54.76s, training loss: 0.027053, test accuracy:0.768756\n",
      "Epoch: 10, time used: 55.05s, training loss: 0.026427, test accuracy:0.774595\n",
      "Epoch: 11, time used: 54.86s, training loss: 0.016715, test accuracy:0.785502\n",
      "Epoch: 12, time used: 54.95s, training loss: 0.013570, test accuracy:0.786053\n",
      "Epoch: 13, time used: 55.16s, training loss: 0.013123, test accuracy:0.785832\n",
      "Epoch: 14, time used: 55.10s, training loss: 0.012982, test accuracy:0.782087\n",
      "Epoch: 15, time used: 54.84s, training loss: 0.013323, test accuracy:0.785502\n",
      "Epoch: 16, time used: 55.08s, training loss: 0.012893, test accuracy:0.784620\n",
      "Epoch: 17, time used: 54.95s, training loss: 0.012501, test accuracy:0.783519\n",
      "Epoch: 18, time used: 54.66s, training loss: 0.012607, test accuracy:0.785281\n",
      "Epoch: 19, time used: 54.88s, training loss: 0.012748, test accuracy:0.783078\n",
      "Epoch: 20, time used: 55.53s, training loss: 0.012780, test accuracy:0.785392\n"
     ]
    }
   ],
   "source": [
    "trainset = ASLDataset('train',transform=rotation)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=256,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = ASLDataset('test',transform=no_transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "baselineModel = BaselineModel(3).to(device)\n",
    "criterion_b = nn.CrossEntropyLoss()\n",
    "optimizer_b = optim.Adam(baselineModel.parameters(), lr=0.01, weight_decay=0.001)\n",
    "scheduler_b = torch.optim.lr_scheduler.MultiStepLR(optimizer_b, milestones=[4,10,15], gamma=0.1)\n",
    "\n",
    "\n",
    "summary(baselineModel,(3, 200, 200))\n",
    "\n",
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "    start_time = time.time()\n",
    "    train_loss = train(baselineModel, trainloader, criterion_b, optimizer_b, scheduler_b)\n",
    "    test_acc = test(baselineModel, testloader)\n",
    "        \n",
    "    print(f'Epoch: {epoch+1}, time used: {time.time()-start_time:.2f}s, training loss: {train_loss:.6f}, test accuracy:{test_acc:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1d4642-7325-4d8f-ba22-9a618e6b7bea",
   "metadata": {},
   "source": [
    "Resnet style CNN without preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26aba5ae-2f7b-4f28-ae13-4bd9e31a8519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 100, 100]           9,472\n",
      "         MaxPool2d-2           [-1, 64, 50, 50]               0\n",
      "       BatchNorm2d-3           [-1, 64, 50, 50]             128\n",
      "              ReLU-4           [-1, 64, 50, 50]               0\n",
      "            Conv2d-5          [-1, 128, 25, 25]           8,320\n",
      "       BatchNorm2d-6          [-1, 128, 25, 25]             256\n",
      "            Conv2d-7          [-1, 128, 25, 25]          73,856\n",
      "       BatchNorm2d-8          [-1, 128, 25, 25]             256\n",
      "            Conv2d-9          [-1, 128, 25, 25]         147,584\n",
      "      BatchNorm2d-10          [-1, 128, 25, 25]             256\n",
      "         ResBlock-11          [-1, 128, 25, 25]               0\n",
      "           Conv2d-12          [-1, 256, 13, 13]          33,024\n",
      "      BatchNorm2d-13          [-1, 256, 13, 13]             512\n",
      "           Conv2d-14          [-1, 256, 13, 13]         295,168\n",
      "      BatchNorm2d-15          [-1, 256, 13, 13]             512\n",
      "           Conv2d-16          [-1, 256, 13, 13]         590,080\n",
      "      BatchNorm2d-17          [-1, 256, 13, 13]             512\n",
      "         ResBlock-18          [-1, 256, 13, 13]               0\n",
      "AdaptiveAvgPool2d-19            [-1, 256, 1, 1]               0\n",
      "           Linear-20                   [-1, 29]           7,453\n",
      "================================================================\n",
      "Total params: 1,167,389\n",
      "Trainable params: 1,167,389\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.46\n",
      "Forward/backward pass size (MB): 15.13\n",
      "Params size (MB): 4.45\n",
      "Estimated Total Size (MB): 20.04\n",
      "----------------------------------------------------------------\n",
      "Epoch: 1, time used: 43.21s, training loss: 0.926418, test accuracy:0.445852\n",
      "Epoch: 2, time used: 43.11s, training loss: 0.113043, test accuracy:0.511292\n",
      "Epoch: 3, time used: 42.87s, training loss: 0.077777, test accuracy:0.756858\n",
      "Epoch: 4, time used: 42.64s, training loss: 0.072176, test accuracy:0.577283\n",
      "Epoch: 5, time used: 42.65s, training loss: 0.017604, test accuracy:0.822629\n",
      "Epoch: 6, time used: 42.88s, training loss: 0.018622, test accuracy:0.823179\n",
      "Epoch: 7, time used: 43.13s, training loss: 0.019789, test accuracy:0.809849\n",
      "Epoch: 8, time used: 43.49s, training loss: 0.020230, test accuracy:0.816900\n",
      "Epoch: 9, time used: 43.54s, training loss: 0.020342, test accuracy:0.795086\n",
      "Epoch: 10, time used: 42.93s, training loss: 0.021255, test accuracy:0.814476\n",
      "Epoch: 11, time used: 43.38s, training loss: 0.012919, test accuracy:0.811832\n",
      "Epoch: 12, time used: 43.40s, training loss: 0.012302, test accuracy:0.807425\n",
      "Epoch: 13, time used: 43.11s, training loss: 0.012612, test accuracy:0.813485\n",
      "Epoch: 14, time used: 42.62s, training loss: 0.013240, test accuracy:0.815688\n",
      "Epoch: 15, time used: 43.45s, training loss: 0.013672, test accuracy:0.814146\n",
      "Epoch: 16, time used: 43.32s, training loss: 0.013158, test accuracy:0.813264\n",
      "Epoch: 17, time used: 43.29s, training loss: 0.013103, test accuracy:0.806985\n",
      "Epoch: 18, time used: 43.13s, training loss: 0.013190, test accuracy:0.809188\n",
      "Epoch: 19, time used: 43.02s, training loss: 0.013189, test accuracy:0.808968\n",
      "Epoch: 20, time used: 42.71s, training loss: 0.013175, test accuracy:0.811171\n"
     ]
    }
   ],
   "source": [
    "trainset = ASLDataset('train',transform=no_transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=256,\n",
    "                                          shuffle=True, num_workers=1)\n",
    "\n",
    "testset = ASLDataset('test',transform=no_transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "                                         shuffle=False, num_workers=1)\n",
    "\n",
    "resNetStyle = ResNetStyle(3).to(device)\n",
    "criterion_r = nn.CrossEntropyLoss()\n",
    "optimizer_r = optim.Adam(resNetStyle.parameters(), lr=0.01, weight_decay=0.001)\n",
    "scheduler_r = torch.optim.lr_scheduler.MultiStepLR(optimizer_r, milestones=[4,10,15], gamma=0.1)\n",
    "\n",
    "\n",
    "summary(resNetStyle,(3, 200, 200))\n",
    "\n",
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "    start_time = time.time()\n",
    "    train_loss = train(resNetStyle, trainloader, criterion_r, optimizer_r, scheduler_r)\n",
    "    test_acc = test(resNetStyle, testloader)\n",
    "        \n",
    "    print(f'Epoch: {epoch+1}, time used: {time.time()-start_time:.2f}s, training loss: {train_loss:.6f}, test accuracy:{test_acc:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36591595-783d-4695-b0ec-de580e26388c",
   "metadata": {},
   "source": [
    "Resnet style CNN without grayscale images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb8b99f5-b24e-4d11-bdcf-420a673ba54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 100, 100]           3,200\n",
      "         MaxPool2d-2           [-1, 64, 50, 50]               0\n",
      "       BatchNorm2d-3           [-1, 64, 50, 50]             128\n",
      "              ReLU-4           [-1, 64, 50, 50]               0\n",
      "            Conv2d-5          [-1, 128, 25, 25]           8,320\n",
      "       BatchNorm2d-6          [-1, 128, 25, 25]             256\n",
      "            Conv2d-7          [-1, 128, 25, 25]          73,856\n",
      "       BatchNorm2d-8          [-1, 128, 25, 25]             256\n",
      "            Conv2d-9          [-1, 128, 25, 25]         147,584\n",
      "      BatchNorm2d-10          [-1, 128, 25, 25]             256\n",
      "         ResBlock-11          [-1, 128, 25, 25]               0\n",
      "           Conv2d-12          [-1, 256, 13, 13]          33,024\n",
      "      BatchNorm2d-13          [-1, 256, 13, 13]             512\n",
      "           Conv2d-14          [-1, 256, 13, 13]         295,168\n",
      "      BatchNorm2d-15          [-1, 256, 13, 13]             512\n",
      "           Conv2d-16          [-1, 256, 13, 13]         590,080\n",
      "      BatchNorm2d-17          [-1, 256, 13, 13]             512\n",
      "         ResBlock-18          [-1, 256, 13, 13]               0\n",
      "AdaptiveAvgPool2d-19            [-1, 256, 1, 1]               0\n",
      "           Linear-20                   [-1, 29]           7,453\n",
      "================================================================\n",
      "Total params: 1,161,117\n",
      "Trainable params: 1,161,117\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.15\n",
      "Forward/backward pass size (MB): 15.13\n",
      "Params size (MB): 4.43\n",
      "Estimated Total Size (MB): 19.71\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# trainset = ASLDataset('train',transform=grayscale)\n",
    "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=256,\n",
    "#                                           shuffle=True, num_workers=1)\n",
    "\n",
    "# testset = ASLDataset('test',transform=grayscale)\n",
    "# testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "#                                          shuffle=False, num_workers=1)\n",
    "\n",
    "resNetStyle = ResNetStyle(1).to(device)\n",
    "# criterion_r = nn.CrossEntropyLoss()\n",
    "# optimizer_r = optim.Adam(resNetStyle.parameters(), lr=0.01, weight_decay=0.001)\n",
    "# scheduler_r = torch.optim.lr_scheduler.MultiStepLR(optimizer_r, milestones=[4,10,15], gamma=0.1)\n",
    "\n",
    "\n",
    "summary(resNetStyle,(1, 200, 200))\n",
    "\n",
    "# for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "#     start_time = time.time()\n",
    "#     train_loss = train(resNetStyle, trainloader, criterion_r, optimizer_r, scheduler_r)\n",
    "#     test_acc = test(resNetStyle, testloader)\n",
    "        \n",
    "#     print(f'Epoch: {epoch+1}, time used: {time.time()-start_time:.2f}s, training loss: {train_loss:.6f}, test accuracy:{test_acc:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f428625-15d5-410d-9e8a-58011543490a",
   "metadata": {},
   "source": [
    "Inception style CNN without preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fada69c9-4bda-4947-bae7-cf04dbc55c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 100, 100]           9,472\n",
      "       BatchNorm2d-2         [-1, 64, 100, 100]             128\n",
      "              ReLU-3         [-1, 64, 100, 100]               0\n",
      "         ConvBlock-4         [-1, 64, 100, 100]               0\n",
      "         MaxPool2d-5           [-1, 64, 50, 50]               0\n",
      "            Conv2d-6          [-1, 192, 50, 50]         110,784\n",
      "       BatchNorm2d-7          [-1, 192, 50, 50]             384\n",
      "              ReLU-8          [-1, 192, 50, 50]               0\n",
      "         ConvBlock-9          [-1, 192, 50, 50]               0\n",
      "        MaxPool2d-10          [-1, 192, 25, 25]               0\n",
      "           Conv2d-11           [-1, 64, 25, 25]          12,352\n",
      "      BatchNorm2d-12           [-1, 64, 25, 25]             128\n",
      "             ReLU-13           [-1, 64, 25, 25]               0\n",
      "        ConvBlock-14           [-1, 64, 25, 25]               0\n",
      "           Conv2d-15           [-1, 96, 25, 25]          18,528\n",
      "      BatchNorm2d-16           [-1, 96, 25, 25]             192\n",
      "             ReLU-17           [-1, 96, 25, 25]               0\n",
      "        ConvBlock-18           [-1, 96, 25, 25]               0\n",
      "           Conv2d-19          [-1, 128, 25, 25]         110,720\n",
      "      BatchNorm2d-20          [-1, 128, 25, 25]             256\n",
      "             ReLU-21          [-1, 128, 25, 25]               0\n",
      "        ConvBlock-22          [-1, 128, 25, 25]               0\n",
      "           Conv2d-23           [-1, 16, 25, 25]           3,088\n",
      "      BatchNorm2d-24           [-1, 16, 25, 25]              32\n",
      "             ReLU-25           [-1, 16, 25, 25]               0\n",
      "        ConvBlock-26           [-1, 16, 25, 25]               0\n",
      "           Conv2d-27           [-1, 32, 25, 25]          12,832\n",
      "      BatchNorm2d-28           [-1, 32, 25, 25]              64\n",
      "             ReLU-29           [-1, 32, 25, 25]               0\n",
      "        ConvBlock-30           [-1, 32, 25, 25]               0\n",
      "        MaxPool2d-31          [-1, 192, 25, 25]               0\n",
      "           Conv2d-32           [-1, 32, 25, 25]           6,176\n",
      "      BatchNorm2d-33           [-1, 32, 25, 25]              64\n",
      "             ReLU-34           [-1, 32, 25, 25]               0\n",
      "        ConvBlock-35           [-1, 32, 25, 25]               0\n",
      "   InceptionBlock-36          [-1, 256, 25, 25]               0\n",
      "           Conv2d-37          [-1, 128, 25, 25]          32,896\n",
      "      BatchNorm2d-38          [-1, 128, 25, 25]             256\n",
      "             ReLU-39          [-1, 128, 25, 25]               0\n",
      "        ConvBlock-40          [-1, 128, 25, 25]               0\n",
      "           Conv2d-41          [-1, 128, 25, 25]          32,896\n",
      "      BatchNorm2d-42          [-1, 128, 25, 25]             256\n",
      "             ReLU-43          [-1, 128, 25, 25]               0\n",
      "        ConvBlock-44          [-1, 128, 25, 25]               0\n",
      "           Conv2d-45          [-1, 192, 25, 25]         221,376\n",
      "      BatchNorm2d-46          [-1, 192, 25, 25]             384\n",
      "             ReLU-47          [-1, 192, 25, 25]               0\n",
      "        ConvBlock-48          [-1, 192, 25, 25]               0\n",
      "           Conv2d-49           [-1, 32, 25, 25]           8,224\n",
      "      BatchNorm2d-50           [-1, 32, 25, 25]              64\n",
      "             ReLU-51           [-1, 32, 25, 25]               0\n",
      "        ConvBlock-52           [-1, 32, 25, 25]               0\n",
      "           Conv2d-53           [-1, 96, 25, 25]          76,896\n",
      "      BatchNorm2d-54           [-1, 96, 25, 25]             192\n",
      "             ReLU-55           [-1, 96, 25, 25]               0\n",
      "        ConvBlock-56           [-1, 96, 25, 25]               0\n",
      "        MaxPool2d-57          [-1, 256, 25, 25]               0\n",
      "           Conv2d-58           [-1, 64, 25, 25]          16,448\n",
      "      BatchNorm2d-59           [-1, 64, 25, 25]             128\n",
      "             ReLU-60           [-1, 64, 25, 25]               0\n",
      "        ConvBlock-61           [-1, 64, 25, 25]               0\n",
      "   InceptionBlock-62          [-1, 480, 25, 25]               0\n",
      "AdaptiveAvgPool2d-63            [-1, 480, 1, 1]               0\n",
      "           Linear-64                   [-1, 29]          13,949\n",
      "================================================================\n",
      "Total params: 689,165\n",
      "Trainable params: 689,165\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.46\n",
      "Forward/backward pass size (MB): 61.19\n",
      "Params size (MB): 2.63\n",
      "Estimated Total Size (MB): 64.28\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# trainset = ASLDataset('train',transform=no_transform)\n",
    "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=256,\n",
    "#                                           shuffle=True, num_workers=2)\n",
    "\n",
    "# testset = ASLDataset('test',transform=no_transform)\n",
    "# testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "#                                          shuffle=False, num_workers=2)\n",
    "inceptionStyle = InceptionStyle(3).to(device)\n",
    "# criterion_i = nn.CrossEntropyLoss()\n",
    "# optimizer_i = optim.Adam(inceptionStyle.parameters(), lr=0.01, weight_decay=0.001)\n",
    "# scheduler_i = torch.optim.lr_scheduler.MultiStepLR(optimizer_i, milestones=[4,10,15], gamma=0.1)\n",
    "\n",
    "\n",
    "summary(inceptionStyle,(3, 200, 200))\n",
    "\n",
    "# for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "#     start_time = time.time()\n",
    "#     train_loss = train(inceptionStyle, trainloader, criterion_i, optimizer_i, scheduler_i)\n",
    "#     test_acc = test(inceptionStyle, testloader)\n",
    "        \n",
    "#     print(f'Epoch: {epoch+1}, time used: {time.time()-start_time:.2f}s, training loss: {train_loss:.6f}, test accuracy:{test_acc:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15693954-b832-43d3-8d8f-f3536599074f",
   "metadata": {},
   "source": [
    "Inception style CNN with grayscale images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e285ca57-568e-49cc-9ccf-db943e56c060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainset = ASLDataset('train',transform=grayscale)\n",
    "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=256,\n",
    "#                                           shuffle=True, num_workers=2)\n",
    "\n",
    "# testset = ASLDataset('test',transform=grayscale)\n",
    "# testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "#                                          shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "# inceptionStyle = InceptionStyle(1).to(device)\n",
    "# criterion_i = nn.CrossEntropyLoss()\n",
    "# optimizer_i = optim.Adam(inceptionStyle.parameters(), lr=0.01, weight_decay=0.001)\n",
    "# scheduler_i = torch.optim.lr_scheduler.MultiStepLR(optimizer_i, milestones=[4,10,15], gamma=0.1)\n",
    "\n",
    "\n",
    "# summary(inceptionStyle,(1, 200, 200))\n",
    "\n",
    "# for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "#     start_time = time.time()\n",
    "#     train_loss = train(inceptionStyle, trainloader, criterion_i, optimizer_i, scheduler_i)\n",
    "#     test_acc = test(inceptionStyle, testloader)\n",
    "        \n",
    "#     print(f'Epoch: {epoch+1}, time used: {time.time()-start_time:.2f}s, training loss: {train_loss:.6f}, test accuracy:{test_acc:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a78d4f5-3710-48c7-a987-69ff6b193f59",
   "metadata": {},
   "source": [
    "Transfer learning using the Resnet18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66db1236-0552-43cc-8c6a-6379e4e474fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224,224)),\n",
    "    # transforms.Gray(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]\n",
    ")\n",
    "\n",
    "trainset = ASLDataset('train',transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=256,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = ASLDataset('test',transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a2cedaf-575a-4ee2-a89e-774108f0ae35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=29, bias=True)\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
      "             ReLU-21          [-1, 128, 28, 28]               0\n",
      "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
      "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
      "             ReLU-26          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
      "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
      "             ReLU-30          [-1, 128, 28, 28]               0\n",
      "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
      "             ReLU-33          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
      "             ReLU-37          [-1, 256, 14, 14]               0\n",
      "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
      "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
      "             ReLU-42          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
      "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
      "             ReLU-46          [-1, 256, 14, 14]               0\n",
      "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
      "             ReLU-49          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
      "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-53            [-1, 512, 7, 7]               0\n",
      "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-58            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
      "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-62            [-1, 512, 7, 7]               0\n",
      "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-65            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                   [-1, 29]          14,877\n",
      "================================================================\n",
      "Total params: 11,191,389\n",
      "Trainable params: 8,408,605\n",
      "Non-trainable params: 2,782,784\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 62.79\n",
      "Params size (MB): 42.69\n",
      "Estimated Total Size (MB): 106.05\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "resnet = models.resnet18(pretrained=True)\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in resnet.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "\n",
    "num_ftrs = resnet.fc.in_features\n",
    "resnet.fc = nn.Linear(num_ftrs, 29)\n",
    "resnet.to(device)\n",
    "print(resnet)\n",
    "summary(resnet, (3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a37cc22-ad79-4ab4-8e3c-428e77f74581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, time used: 51.59s, training loss: 0.227141, test accuracy:0.819764\n",
      "Epoch: 2, time used: 51.58s, training loss: 0.063689, test accuracy:0.509199\n",
      "Epoch: 3, time used: 51.62s, training loss: 0.053848, test accuracy:0.616063\n",
      "Epoch: 4, time used: 51.55s, training loss: 0.049236, test accuracy:0.796629\n",
      "Epoch: 5, time used: 51.57s, training loss: 0.010127, test accuracy:0.912196\n",
      "Epoch: 6, time used: 51.69s, training loss: 0.008702, test accuracy:0.905916\n",
      "Epoch: 7, time used: 51.69s, training loss: 0.009722, test accuracy:0.919907\n",
      "Epoch: 8, time used: 51.76s, training loss: 0.010962, test accuracy:0.870332\n",
      "Epoch: 9, time used: 51.62s, training loss: 0.013492, test accuracy:0.843891\n",
      "Epoch: 10, time used: 51.63s, training loss: 0.011440, test accuracy:0.908560\n",
      "Epoch: 11, time used: 51.66s, training loss: 0.006538, test accuracy:0.913958\n",
      "Epoch: 12, time used: 51.64s, training loss: 0.006113, test accuracy:0.913297\n",
      "Epoch: 13, time used: 51.72s, training loss: 0.006461, test accuracy:0.912857\n",
      "Epoch: 14, time used: 51.66s, training loss: 0.006790, test accuracy:0.912306\n",
      "Epoch: 15, time used: 51.65s, training loss: 0.007033, test accuracy:0.913077\n",
      "Epoch: 16, time used: 51.71s, training loss: 0.006924, test accuracy:0.912416\n",
      "Epoch: 17, time used: 51.68s, training loss: 0.007016, test accuracy:0.911865\n",
      "Epoch: 18, time used: 51.60s, training loss: 0.006940, test accuracy:0.912196\n",
      "Epoch: 19, time used: 51.63s, training loss: 0.006870, test accuracy:0.910653\n",
      "Epoch: 20, time used: 51.63s, training loss: 0.007008, test accuracy:0.912196\n"
     ]
    }
   ],
   "source": [
    "criterion_t_r = nn.CrossEntropyLoss()\n",
    "optimizer_t_r = optim.Adam(filter(lambda p: p.requires_grad, resnet.parameters()), lr=0.01, weight_decay=0.001)\n",
    "scheduler_t_r = torch.optim.lr_scheduler.MultiStepLR(optimizer_t_r, milestones=[4,10,15], gamma=0.1)\n",
    "\n",
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "    \n",
    "    start_time = time.time()\n",
    "    train_loss = train(resnet, trainloader, criterion_t_r, optimizer_t_r, scheduler_t_r)\n",
    "    test_acc = test(resnet, testloader)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1}, time used: {time.time()-start_time:.2f}s, training loss: {train_loss:.6f}, test accuracy:{test_acc:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a3542a9-2222-42aa-9ba9-a5b183792786",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet.state_dict(), f'./trained_models/resnet_raw.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d996cbc1-8edc-409c-b8e2-2c0c1e739222",
   "metadata": {},
   "source": [
    "Transfer learning using the InceptionV3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ae322c3-7c9c-4f7b-9b85-b40eb072bfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inception = models.inception_v3(pretrained=True)\n",
    "\n",
    "# for param in inception.parameters():\n",
    "#     param.requires_grad = False\n",
    "# for param in inception.Mixed_7c.parameters():\n",
    "#     param.requires_grad = True\n",
    "    \n",
    "# num_ftrs = inception.fc.in_features\n",
    "# inception.fc = nn.Linear(num_ftrs, 29)\n",
    "# inception.to(device)\n",
    "# print(inception)\n",
    "# summary(inception, (3,299,299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f39bc1ad-342b-4680-8575-37797be9fb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_inc(model, data_loader, criterion, optimizer, scheduler):\n",
    "    \n",
    "#     model.train()\n",
    "#     running_loss = 0.0\n",
    "\n",
    "#     for i, data in enumerate(data_loader, 0):\n",
    "#         inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs, aux_output = model(inputs)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         running_loss += loss.item()\n",
    "    \n",
    "#     scheduler.step()\n",
    "    \n",
    "    \n",
    "#     return running_loss / len(data_loader)\n",
    "\n",
    "\n",
    "# def test_inc(model, dataloader):\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     model.eval()\n",
    "#     # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "#     with torch.no_grad():\n",
    "#         for data in dataloader:\n",
    "#             images, labels = data[0].to(device), data[1].to(device)\n",
    "#             # calculate outputs by running images through the network\n",
    "#             outputs, aux_output = model(images)\n",
    "#             # the class with the highest energy is what we choose as prediction\n",
    "#             _, predicted = torch.max(outputs.data, 1)\n",
    "#             total += labels.size(0)\n",
    "#             correct += (predicted == labels).sum().item()\n",
    "    \n",
    "#     return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b138a358-6765-4026-a070-14b9e3b7c433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = transforms.Compose(\n",
    "#     [transforms.ToTensor(),\n",
    "#      transforms.Resize((299,299)),\n",
    "#      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]\n",
    "# )\n",
    "\n",
    "# trainset = ASLDataset('train',transform=transform)\n",
    "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=256,\n",
    "#                                           shuffle=True, num_workers=2)\n",
    "\n",
    "# testset = ASLDataset('test',transform=transform)\n",
    "# testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "#                                          shuffle=False, num_workers=2)\n",
    "\n",
    "# criterion_t_i = nn.CrossEntropyLoss()\n",
    "# optimizer_t_i = optim.Adam(filter(lambda p: p.requires_grad, inception.parameters()), lr=0.01, weight_decay=0.001)\n",
    "# scheduler_t_i = torch.optim.lr_scheduler.MultiStepLR(optimizer_t_i, milestones=[4,10,15], gamma=0.1)\n",
    "\n",
    "\n",
    "# for epoch in range(20):  # loop over the dataset multiple times\n",
    "    \n",
    "#     start_time = time.time()\n",
    "#     train_loss = train_inc(inception, trainloader, criterion_t_i, optimizer_t_i, scheduler_t_i)\n",
    "#     test_acc = test(inception, testloader)\n",
    "    \n",
    "#     print(f'Epoch: {epoch+1}, time used: {time.time()-start_time:.2f}s, training loss: {train_loss:.6f}, test accuracy:{test_acc:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0254c5f-1d7a-4295-8c7f-e2194a1bd4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(inception.state_dict(), f'./trained_models/inception_raw.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66810be5-5cfd-42d1-ab2e-c13c0f20a7b1",
   "metadata": {},
   "source": [
    "Transfer learning using the efficientnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20bff1a5-9502-480a-991b-f770f6cafdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# efficientnet = models.efficientnet_b0(pretrained=True)\n",
    "\n",
    "# for param in efficientnet.parameters():\n",
    "#     param.requires_grad = False\n",
    "# for param in efficientnet.features[8].parameters():\n",
    "#     param.requires_grad = True\n",
    "    \n",
    "# num_ftrs = efficientnet.classifier[1].in_features\n",
    "# efficientnet.classifier[1] = nn.Linear(num_ftrs, 29)\n",
    "# efficientnet.to(device)\n",
    "# print(efficientnet)\n",
    "# summary(efficientnet, (3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99f51a71-7d89-4533-824b-d854bc52f557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = transforms.Compose(\n",
    "#     [transforms.ToTensor(),\n",
    "#      transforms.Resize((224,224)),\n",
    "#      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]\n",
    "# )\n",
    "\n",
    "# trainset = ASLDataset('train',transform=transform)\n",
    "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=256,\n",
    "#                                           shuffle=True, num_workers=2)\n",
    "\n",
    "# testset = ASLDataset('test',transform=transform)\n",
    "# testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "#                                          shuffle=False, num_workers=2)\n",
    "\n",
    "# criterion_t_e = nn.CrossEntropyLoss()\n",
    "# optimizer_t_e = optim.Adam(filter(lambda p: p.requires_grad, efficientnet.parameters()), lr=0.01, weight_decay=0.001)\n",
    "# scheduler_t_e = torch.optim.lr_scheduler.MultiStepLR(optimizer_t_e, milestones=[4,10,15], gamma=0.1)\n",
    "\n",
    "\n",
    "# for epoch in range(20):  # loop over the dataset multiple times\n",
    "    \n",
    "#     start_time = time.time()\n",
    "#     train_loss = train(efficientnet, trainloader, criterion_t_e, optimizer_t_e, scheduler_t_e)\n",
    "#     test_acc = test(efficientnet, testloader)\n",
    "    \n",
    "#     print(f'Epoch: {epoch+1}, time used: {time.time()-start_time:.2f}s, training loss: {train_loss:.6f}, test accuracy:{test_acc:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e51118-d4c0-4fe7-a8c3-01845ba8b9ae",
   "metadata": {},
   "source": [
    "Transfer learning using the mobilenet_v3_small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0137776f-c313-451d-8c4b-d2fcbbd505fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mobilenet_v3_small = models.mobilenet_v3_small(pretrained=False)\n",
    "# mobilenet_v3_small.load_state_dict(torch.load('./trained_models/mobilenet_v3_small-047dcff4.pth'))\n",
    "\n",
    "# for param in mobilenet_v3_small.features.parameters():\n",
    "#     param.requires_grad = False\n",
    "# for param in mobilenet_v3_small.features[12].parameters():\n",
    "#     param.requires_grad = True\n",
    "    \n",
    "# num_ftrs = mobilenet_v3_small.classifier[3].in_features\n",
    "# mobilenet_v3_small.classifier[3] = nn.Linear(num_ftrs, 29)\n",
    "# mobilenet_v3_small.to(device)\n",
    "# print(mobilenet_v3_small)\n",
    "# summary(mobilenet_v3_small, (3,224,224))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b8cedd16-4a17-4268-9deb-c5df092be6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = transforms.Compose(\n",
    "#     [transforms.ToTensor(),\n",
    "#      transforms.Resize((224,224)),\n",
    "#      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]\n",
    "# )\n",
    "\n",
    "# trainset = ASLDataset('train',transform=transform)\n",
    "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=256,\n",
    "#                                           shuffle=True, num_workers=2)\n",
    "\n",
    "# testset = ASLDataset('test',transform=transform)\n",
    "# testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "#                                          shuffle=False, num_workers=2)\n",
    "\n",
    "# criterion_t_m = nn.CrossEntropyLoss()\n",
    "# optimizer_t_m = optim.Adam(filter(lambda p: p.requires_grad, mobilenet_v3_small.parameters()), lr=0.01, weight_decay=0.001)\n",
    "# scheduler_t_m = torch.optim.lr_scheduler.MultiStepLR(optimizer_t_m, milestones=[4,10,15], gamma=0.1)\n",
    "\n",
    "\n",
    "# for epoch in range(20):  # loop over the dataset multiple times\n",
    "    \n",
    "#     start_time = time.time()\n",
    "#     train_loss = train(mobilenet_v3_small, trainloader, criterion_t_m, optimizer_t_m, scheduler_t_m)\n",
    "#     test_acc = test(mobilenet_v3_small, testloader)\n",
    "    \n",
    "#     print(f'Epoch: {epoch+1}, time used: {time.time()-start_time:.2f}s, training loss: {train_loss:.6f}, test accuracy:{test_acc:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96fa2d1-8313-4cfc-b1d1-a4b6768d222a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('cnn2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "53b1cc22c89150dad8df01a0b7e8e9b3f92e60ec72dccd9137866dd2a3a9ae73"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
